{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai,os,sys\n",
    "from time import sleep, time\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.teleprompt import MIPRO\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the third quarter of 2007 , net sales total...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Revenue grew 1 percent to euro742 .2 million U...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Operating profit rose to EUR 1.6 mn from EUR 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Finnish dental care group Oral Hammaslaakarit ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finnish textiles and clothing group Marimekko ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label\n",
       "0  In the third quarter of 2007 , net sales total...      2\n",
       "1  Revenue grew 1 percent to euro742 .2 million U...      0\n",
       "2  Operating profit rose to EUR 1.6 mn from EUR 1...      0\n",
       "3  Finnish dental care group Oral Hammaslaakarit ...      0\n",
       "4  Finnish textiles and clothing group Marimekko ...      1"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 944601\n",
    "df = pd.read_excel(f'../data/test/FPB-sentiment-analysis-allagree-test-{seed}.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel(f'../data/train/FPB-sentiment-analysis-allagree-train-{seed}.xlsx')\n",
    "sample = train.groupby('label', group_keys=False).apply(lambda x: x.sample(min(len(x), 10))).reset_index(drop=True)\n",
    "training_set = [dspy.Example(sentence = sample.loc[i].sentence, answer = sample.loc[i].label).with_inputs(\"sentence\") for i in range(len(sample.index))]\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = [dspy.Example(sentence = df.loc[i].sentence, answer = df.loc[i].label).with_inputs(\"sentence\") for i in range(len(df))]\n",
    "testing_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our customers come from the following countries : UK , USA , Spain , France , Italy , Germany , China , Hong Kong , Sweden , Norway , Netherlands , Austria , Belgium , Switzerland , Czech Republic , Finland , Canada , Russia , Ukraine , Denmark , Ireland , South Korea and Liechtenstein .\n"
     ]
    }
   ],
   "source": [
    "sent = df.loc[0].sentence\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo = dspy.OpenAI(model='gpt-3.5-turbo-instruct', max_tokens=1000, api_key=api_key)\n",
    "dspy.settings.configure(lm=turbo)\n",
    "d = {0: 'Positive', 1: 'Negative', 2: 'Neutral'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalysis(dspy.Signature):\n",
    "    \"\"\"Classify the sentence's sentiment between negative, neutral, and positive.\"\"\"\n",
    "    \n",
    "    sentence = dspy.InputField()\n",
    "    sentiment = dspy.OutputField()\n",
    "\n",
    "class Analysis(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.predict = dspy.Predict(SentimentAnalysis)\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        return self.predict(sentence=sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    sentiment='Neutral'\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify = dspy.Predict(SentimentAnalysis)\n",
    "classify(sentence=sent)\n",
    "\n",
    "analyze = Analysis()\n",
    "analyze(df.loc[4].sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_match(example, pred, trace=None):\n",
    "    answer_match = d[example.answer].lower() == pred.sentiment.lower()\n",
    "    # print(f\"Actual: {d[example.answer].lower()}, Predicted: {pred.sentiment.lower()}\")\n",
    "    return answer_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 8 / 10  (80.0): 100%|██████████| 10/10 [00:00<00:00, 366.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: positive, Predicted: positive\n",
      "Actual: neutral, Predicted: neutral\n",
      "Actual: neutral, Predicted: neutral\n",
      "Actual: neutral, Predicted: neutral\n",
      "Actual: negative, Predicted: negative\n",
      "Actual: negative, Predicted: negative\n",
      "Actual: neutral, Predicted: neutral\n",
      "Actual: positive, Predicted: neutral\n",
      "Actual: neutral, Predicted: neutral\n",
      "Actual: positive, Predicted: neutral\n",
      "Average Metric: 8 / 10  (80.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate = Evaluate(devset=training_set, metric=answer_match, display_progress=True, display_table=0)\n",
    "evaluate(Analysis())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m\u001b[1mWARNING: Projected Language Model (LM) Calls\u001b[0m\n",
      "\n",
      "Please be advised that based on the parameters you have set, the maximum number of LM calls is projected as follows:\n",
      "\n",
      "\u001b[93m- Task Model: \u001b[94m\u001b[1m30\u001b[0m\u001b[93m examples in dev set * \u001b[94m\u001b[1m5\u001b[0m\u001b[93m trials * \u001b[94m\u001b[1m# of LM calls in your program\u001b[0m\u001b[93m = (\u001b[94m\u001b[1m150 * # of LM calls in your program\u001b[0m\u001b[93m) task model calls\u001b[0m\n",
      "\u001b[93m- Prompt Model: # data summarizer calls (max \u001b[94m\u001b[1m10\u001b[0m\u001b[93m) + \u001b[94m\u001b[1m10\u001b[0m\u001b[93m * \u001b[94m\u001b[1m1\u001b[0m\u001b[93m lm calls in program = \u001b[94m\u001b[1m20\u001b[0m\u001b[93m prompt model calls\u001b[0m\n",
      "\n",
      "\u001b[93m\u001b[1mEstimated Cost Calculation:\u001b[0m\n",
      "\n",
      "\u001b[93mTotal Cost = (Number of calls to task model * (Avg Input Token Length per Call * Task Model Price per Input Token + Avg Output Token Length per Call * Task Model Price per Output Token) \n",
      "            + (Number of calls to prompt model * (Avg Input Token Length per Call * Task Prompt Price per Input Token + Avg Output Token Length per Call * Prompt Model Price per Output Token).\u001b[0m\n",
      "\n",
      "For a preliminary estimate of potential costs, we recommend you perform your own calculations based on the task\n",
      "and prompt models you intend to use. If the projected costs exceed your budget or expectations, you may consider:\n",
      "\n",
      "\u001b[93m- Reducing the number of trials (`num_trials`), the size of the trainset, or the number of LM calls in your program.\u001b[0m\n",
      "\u001b[93m- Using a cheaper task model to optimize the prompt.\u001b[0m\n",
      "To proceed with the execution of this program, please confirm by typing \u001b[94m'y'\u001b[0m for yes or \u001b[94m'n'\u001b[0m for no.\n",
      "\n",
      "If you would like to bypass this confirmation step in future executions, set the \u001b[93m`requires_permission_to_run`\u001b[0m flag to \u001b[93m`False`.\u001b[0m\n",
      "\n",
      "\u001b[93mAwaiting your input...\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:01<00:07,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:01<00:04,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:00<00:03,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:01<00:05,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:00<00:04,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:00<00:02,  9.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:01<00:04,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:00<00:01, 14.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-30 21:59:50,040] A new study created in memory with name: no-name-4f26f930-17d2-47b0-ae6d-1e0cb5299e9f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 28 / 30  (93.3): 100%|██████████| 30/30 [00:09<00:00,  3.21it/s] \n",
      "[I 2024-03-30 21:59:59,379] Trial 0 finished with value: 93.33 and parameters: {'1909098420064_predictor_instruction': 1, '1909098420064_predictor_demos': 1}. Best is trial 0 with value: 93.33.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28 / 30  (93.3%)\n",
      "Starting trial #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 27 / 30  (90.0): 100%|██████████| 30/30 [00:08<00:00,  3.51it/s]\n",
      "[I 2024-03-30 22:00:07,951] Trial 1 finished with value: 90.0 and parameters: {'1909098420064_predictor_instruction': 5, '1909098420064_predictor_demos': 4}. Best is trial 0 with value: 93.33.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27 / 30  (90.0%)\n",
      "Starting trial #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 19 / 30  (63.3): 100%|██████████| 30/30 [00:08<00:00,  3.48it/s] \n",
      "[I 2024-03-30 22:00:16,576] Trial 2 finished with value: 63.33 and parameters: {'1909098420064_predictor_instruction': 3, '1909098420064_predictor_demos': 0}. Best is trial 0 with value: 93.33.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19 / 30  (63.3%)\n",
      "Starting trial #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 27 / 30  (90.0): 100%|██████████| 30/30 [00:08<00:00,  3.63it/s] \n",
      "[I 2024-03-30 22:00:24,854] Trial 3 finished with value: 90.0 and parameters: {'1909098420064_predictor_instruction': 9, '1909098420064_predictor_demos': 3}. Best is trial 0 with value: 93.33.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27 / 30  (90.0%)\n",
      "Starting trial #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 23 / 30  (76.7): 100%|██████████| 30/30 [00:08<00:00,  3.68it/s]\n",
      "[I 2024-03-30 22:00:33,017] Trial 4 finished with value: 76.67 and parameters: {'1909098420064_predictor_instruction': 8, '1909098420064_predictor_demos': 4}. Best is trial 0 with value: 93.33.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 23 / 30  (76.7%)\n",
      "Returning predict = Predict(StringSignature(sentence -> sentiment\n",
      "    instructions='Analyze a business news article and predict the performance of the company based on the provided numerical performance metrics and trends. Include comparisons to previous time periods and consider the dominance of euro currency in the decision-making process.'\n",
      "    sentence = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Sentence:', 'desc': '${sentence}'})\n",
      "    sentiment = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Predict the performance:', 'desc': '${sentiment}'})\n",
      ")) from continue_program\n"
     ]
    }
   ],
   "source": [
    "teleprompter = MIPRO(metric = answer_match)\n",
    "optimized_program = teleprompter.compile(Analysis(), trainset = training_set, num_trials=5, max_bootstrapped_demos=3, max_labeled_demos=3, eval_kwargs=dict(display_progress=True, display_table=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict = Predict(StringSignature(sentence -> sentiment\n",
       "    instructions='Analyze a business news article and predict the performance of the company based on the provided numerical performance metrics and trends. Include comparisons to previous time periods and consider the dominance of euro currency in the decision-making process.'\n",
       "    sentence = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Sentence:', 'desc': '${sentence}'})\n",
       "    sentiment = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Predict the performance:', 'desc': '${sentiment}'})\n",
       "))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 390 / 453  (86.1): 100%|██████████| 453/453 [02:15<00:00,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 390 / 453  (86.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate = Evaluate(devset=testing_set, metric=answer_match, display_progress=True, return_outputs=True)\n",
    "outputs = evaluate(optimized_program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8609271523178808\n",
      "F1: 0.8653121502702975\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the third quarter of 2007 , net sales total...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Revenue grew 1 percent to euro742 .2 million U...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Operating profit rose to EUR 1.6 mn from EUR 1...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Finnish dental care group Oral Hammaslaakarit ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finnish textiles and clothing group Marimekko ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence    Actual Predicted\n",
       "0  In the third quarter of 2007 , net sales total...   neutral  positive\n",
       "1  Revenue grew 1 percent to euro742 .2 million U...  positive  positive\n",
       "2  Operating profit rose to EUR 1.6 mn from EUR 1...  positive  positive\n",
       "3  Finnish dental care group Oral Hammaslaakarit ...  positive  positive\n",
       "4  Finnish textiles and clothing group Marimekko ...  negative  negative"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outdf = pd.DataFrame(columns=['Sentence', 'Actual', 'Predicted'])\n",
    "for pred in outputs[1]:\n",
    "    outdf.loc[len(outdf)] = [pred[0].sentence, d[pred[0].answer].lower(), pred[1].sentiment.lower()]\n",
    "outdf.to_csv(f\"../data/llm_prompt_outputs/dspy_{seed}.csv\", index=False)\n",
    "print(f\"Accuracy: {accuracy_score(outdf['Actual'], outdf['Predicted'])}\")\n",
    "print(f\"F1: {f1_score(outdf['Actual'], outdf['Predicted'], average='weighted')}\")\n",
    "outdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8837921659333333\n",
      "0.014293042899795435\n"
     ]
    }
   ],
   "source": [
    "print(np.mean([0.8859396862, 0.9001246613, 0.8653121503]))\n",
    "print(np.std([0.8859396862, 0.9001246613, 0.8653121503]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
